{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may add additional imports\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from csv file\n",
    "col_names = []\n",
    "for i in range(33):\n",
    "    if i == 0:\n",
    "        col_names.append('State')\n",
    "    if i == 1:\n",
    "        col_names.append('Fips')\n",
    "    if i == 2:\n",
    "        col_names.append('County')\n",
    "    if i == 3:\n",
    "        col_names.append('Votes')\n",
    "    if i == 4:\n",
    "        col_names.append('Republicans 2016')\n",
    "    if i == 5:\n",
    "        col_names.append('Democrats 2016')\n",
    "    if i == 6:\n",
    "        col_names.append('Republicans 2012')\n",
    "    if i == 7:\n",
    "        col_names.append('Republicans 2008')\n",
    "    if i == 8:\n",
    "        col_names.append('Democrats 2012')\n",
    "    if i == 9:\n",
    "        col_names.append('Democrats 2008')\n",
    "    if i == 10:\n",
    "        col_names.append('Less Than High School Diploma')\n",
    "    if i == 11:\n",
    "        col_names.append('At Least High School Diploma')\n",
    "    if i == 12:\n",
    "        col_names.append('At Least Bachelors Degree')\n",
    "    if i == 13:\n",
    "        col_names.append('Graduate Degree')\n",
    "    if i == 14:\n",
    "        col_names.append('Median Earnings 2010')\n",
    "    if i == 15:\n",
    "        col_names.append('Total Population')\n",
    "    if i == 16:\n",
    "        col_names.append('Poverty Rate below federal poverty threshold')\n",
    "    if i == 17:\n",
    "        col_names.append('Management professional and related occupations')\n",
    "    if i == 18:\n",
    "        col_names.append('Service occupations')\n",
    "    if i == 19:\n",
    "        col_names.append('Sales and office occupations')\n",
    "    if i == 20:\n",
    "        col_names.append('Farming fishing and forestry occupations')\n",
    "    if i == 21:\n",
    "        col_names.append('Construction extraction maintenance and repair occupations')\n",
    "    if i == 22:\n",
    "        col_names.append('Production transportation and material moving occupations')\n",
    "    if i == 23:\n",
    "        col_names.append('White')\n",
    "    if i == 24:\n",
    "        col_names.append('Black')\n",
    "    if i == 25:\n",
    "        col_names.append('Hispanic')\n",
    "    if i == 26:\n",
    "        col_names.append('Asian')\n",
    "    if i == 27:\n",
    "        col_names.append('Amerindian')\n",
    "    if i == 28:\n",
    "        col_names.append('Other Race')\n",
    "    if i == 29:\n",
    "        col_names.append('Median Age')\n",
    "    if i == 30:\n",
    "        col_names.append('Uninsured')\n",
    "    if i == 31:\n",
    "        col_names.append('Unemployment')\n",
    "    if i == 32:\n",
    "        col_names.append('Violent crime')\n",
    "        \n",
    "data = pd.read_csv(\"2016_election_dataset.csv\", names = col_names, index_col=False)\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Republican is 0, Democrat is 1\n",
    "def label_party (row):\n",
    "    if row['Republicans 2016'] > row['Democrats 2016']:\n",
    "        return 0\n",
    "    if row['Republicans 2016'] < row['Democrats 2016']:\n",
    "        return 1\n",
    "    if row['Republicans 2016'] == row['Democrats 2016']:\n",
    "        return None\n",
    "    \n",
    "def convertToNumber (s):\n",
    "    return int.from_bytes(s.encode(), 'little')\n",
    "\n",
    "# add label\n",
    "data['Party Label'] = data.apply (lambda row: label_party(row), axis=1)\n",
    "\n",
    "states = {\n",
    "        'AK': 1,'AL': 2,'AR': 3,'AS': 4,'AZ': 5,'CA': 6,'CO': 7,'CT': 8,'DC': 9,'DE': 10,'FL': 11,'GA': 12,'GU': 13,'HI': 14,\n",
    "        'IA': 15,'ID': 16,'IL': 17,'IN': 18,'KS': 19,'KY': 20,'LA': 21,'MA': 22,'MD': 23,'ME': 24,'MI': 25,'MN': 26,'MO': 27,\n",
    "        'MP': 28,'MS': 29,'MT': 30,'NA': 31,'NC': 32,'ND': 33,'NE': 34,'NH': 35,'NJ': 36,'NM': 37,'NV': 38,'NY': 39,'OH': 40,\n",
    "        'OK': 41,'OR': 42,'PA': 43,'PR': 44,'RI': 45,'SC': 46,'SD': 47,'TN': 48,'TX': 49,'UT': 50,'VA': 51,'VI': 52, 'VT': 53,\n",
    "        'WA': 54,'WI': 55,'WV': 56,'WY': 57\n",
    "}\n",
    "data['State']=data['State'].map(states)\n",
    "\n",
    "data = data.drop('County', axis=1)\n",
    "data = data.drop('Republicans 2016', axis=1)\n",
    "data = data.drop('Democrats 2016', axis=1)\n",
    "\n",
    "#just some test, accuracy drops to 89%, so not much really.\n",
    "# data = data.drop('Republicans 2012', axis=1)\n",
    "# data = data.drop('Democrats 2012', axis=1)\n",
    "# data = data.drop('Republicans 2008', axis=1)\n",
    "# data = data.drop('Democrats 2008', axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "proba = clf.predict_proba(features_test)\n",
    "fpr_result, tpr_result, thresholds = roc_curve(labels_test, proba[:,1])\n",
    "#replace these fpr and tpr with the results of your roc_curve\n",
    "fpr, tpr = fpr_result, tpr_result\n",
    "\n",
    "print(roc_auc_score(labels_test, proba[:,1]))\n",
    "\n",
    "# Do not change this code! This plots the ROC curve.\n",
    "# Just replace the fpr and tpr above with the values from your roc_curve\n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part is with the features we modified and added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voter_turnout (row):\n",
    "    return (row['Votes'] / row['Total Population']) * 100\n",
    "\n",
    "def minority(row):\n",
    "    return (row['Black'] + row['Hispanic'] + row['Asian'] + row['Amerindian'] + row['Other Race'])\n",
    "\n",
    "def professional(row):\n",
    "    return (row['Management professional and related occupations'] + row['Sales and office occupations'])\n",
    "    \n",
    "def manufacturing(row):\n",
    "    return (row['Farming fishing and forestry occupations'] + row['Construction extraction maintenance and repair occupations'] + row['Production transportation and material moving occupations'])\n",
    "    \n",
    "data1 = data.pop('Party Label')    \n",
    "    \n",
    "data['Voter Turnout'] = data.apply (lambda row: voter_turnout(row), axis=1)\n",
    "data['Minority'] = data.apply (lambda row: minority(row), axis=1)\n",
    "data['Professional'] = data.apply (lambda row: professional(row), axis=1)\n",
    "data['Manufacturing'] = data.apply (lambda row: manufacturing(row), axis=1)\n",
    "\n",
    "data = data.drop('Black', axis=1)\n",
    "data = data.drop('Hispanic', axis=1)\n",
    "data = data.drop('Asian', axis=1)\n",
    "data = data.drop('Amerindian', axis=1)\n",
    "data = data.drop('Other Race', axis=1)\n",
    "data = data.drop('Management professional and related occupations', axis=1)\n",
    "data = data.drop('Sales and office occupations', axis=1)\n",
    "data = data.drop('Farming fishing and forestry occupations', axis=1)\n",
    "data = data.drop('Construction extraction maintenance and repair occupations', axis=1)\n",
    "data = data.drop('Production transportation and material moving occupations', axis=1)\n",
    "\n",
    "data['Party Label'] = data1\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "proba = clf.predict_proba(features_test)\n",
    "fpr_result, tpr_result, thresholds = roc_curve(labels_test, proba[:,1])\n",
    "#replace these fpr and tpr with the results of your roc_curve\n",
    "fpr, tpr = fpr_result, tpr_result\n",
    "\n",
    "print(roc_auc_score(labels_test, proba[:,1]))\n",
    "\n",
    "# Do not change this code! This plots the ROC curve.\n",
    "# Just replace the fpr and tpr above with the values from your roc_curve\n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "                    SVM MODEL\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "#THIS SHOULD ALREADY BE DONE   \n",
    "# data_Y = data['Party Label']\n",
    "# data_X = data.drop(['Party Label'],axis=1)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.20)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "scaler = StandardScaler()\n",
    "svc = SVC(gamma='auto')\n",
    "\n",
    "pipeline_svm = Pipeline([('scaler', scaler), ('pca', pca), ('svc', svc)])\n",
    "param_grid = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "y_preds = cross_val_predict(pipeline_svm, features_test, labels_test, cv=10) \n",
    "\n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')\n",
    "print(\"Classification report: \\n\", classification_report(labels_test, y_preds, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "                    NEURAL NET MODEL\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_class = MLPClassifier()\n",
    "pipeline_nn = Pipeline([('scaler', scaler), ('mlp_classifier', mlp_class)])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp_classifier__hidden_layer_sizes': list(range(30, 60, 10)),\n",
    "    'mlp_classifier__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_nn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
