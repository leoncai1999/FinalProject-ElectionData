{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Members: Emily Rude, Ye Sheng, Tiffany Valitis, Leon Cai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Predicting the political affiliations of US Counties\n",
    "\n",
    "The goal of this project is to predict whether a given county in the U.S. leans Democratic or Republican based on characteristics such as age, educational level and racial breakdown, the types of industries that its residents work in, and median income. For the purposes of this project, a county is classified as Democratic if the Democratic presidental candidate had the highest percentage of votes in 2016, and Republican if the Republican presidental candidate had the highest percentage of votes in 2016. The dataset we are using, which shows the Democratic/Republican voting breakdown for every county in the U.S. and the charactersitics of each of these counties can be found [here](https://public.opendatasoft.com/explore/dataset/usa-2016-presidential-election-by-county/export/?disjunctive.state).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may add additional imports\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "While the given dataset includes a vast amount of information on each county, many of these features can be trimmed because either two or more features are closely correlated to each other and thus not all of those features are needed, or there is little or no correlation between those features and a county's political affiliation. The features selected below are the most indicative of a county's political characteristics. The percincts feature was left out for example because the votes feature was a similar indicator of the county's size, and the weather features were left out for example because they were lowly correlated to political affiliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3114, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Fips</th>\n",
       "      <th>County</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2016</th>\n",
       "      <th>Democrats 2016</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>Democrats 2012</th>\n",
       "      <th>Democrats 2008</th>\n",
       "      <th>...</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Amerindian</th>\n",
       "      <th>Other Race</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MN</td>\n",
       "      <td>27017</td>\n",
       "      <td>Carlton County, Minnesota</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>45.185226</td>\n",
       "      <td>46.846448</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>61.775873</td>\n",
       "      <td>62.339422</td>\n",
       "      <td>...</td>\n",
       "      <td>89.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KS</td>\n",
       "      <td>20127</td>\n",
       "      <td>Morris County, Kansas</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.704050</td>\n",
       "      <td>22.819315</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>28.024980</td>\n",
       "      <td>31.925378</td>\n",
       "      <td>...</td>\n",
       "      <td>94.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>OK</td>\n",
       "      <td>40107</td>\n",
       "      <td>Okfuskee County, Oklahoma</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>70.963641</td>\n",
       "      <td>23.976608</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>34.976330</td>\n",
       "      <td>35.896192</td>\n",
       "      <td>...</td>\n",
       "      <td>64.00</td>\n",
       "      <td>9.05</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.95</td>\n",
       "      <td>8.25</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MT</td>\n",
       "      <td>30085</td>\n",
       "      <td>Roosevelt County, Montana</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>49.171902</td>\n",
       "      <td>42.946887</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>56.808279</td>\n",
       "      <td>61.738502</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>53.55</td>\n",
       "      <td>8.90</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NY</td>\n",
       "      <td>36055</td>\n",
       "      <td>Monroe County, New York</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>40.251559</td>\n",
       "      <td>54.366824</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>57.966886</td>\n",
       "      <td>58.180987</td>\n",
       "      <td>...</td>\n",
       "      <td>74.25</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>VA</td>\n",
       "      <td>51117</td>\n",
       "      <td>Mecklenburg County, Virginia</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>54.576003</td>\n",
       "      <td>43.295777</td>\n",
       "      <td>52.881873</td>\n",
       "      <td>51.829996</td>\n",
       "      <td>45.904358</td>\n",
       "      <td>47.255006</td>\n",
       "      <td>...</td>\n",
       "      <td>58.95</td>\n",
       "      <td>36.95</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.05</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.098</td>\n",
       "      <td>193.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>GA</td>\n",
       "      <td>13143</td>\n",
       "      <td>Haralson County, Georgia</td>\n",
       "      <td>11317.0</td>\n",
       "      <td>84.642573</td>\n",
       "      <td>13.024653</td>\n",
       "      <td>81.399383</td>\n",
       "      <td>78.021087</td>\n",
       "      <td>17.241712</td>\n",
       "      <td>20.257727</td>\n",
       "      <td>...</td>\n",
       "      <td>91.50</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.095</td>\n",
       "      <td>522.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ME</td>\n",
       "      <td>23017</td>\n",
       "      <td>Oxford County, Maine</td>\n",
       "      <td>31094.0</td>\n",
       "      <td>52.145108</td>\n",
       "      <td>39.145816</td>\n",
       "      <td>40.774983</td>\n",
       "      <td>40.641390</td>\n",
       "      <td>55.506458</td>\n",
       "      <td>56.682464</td>\n",
       "      <td>...</td>\n",
       "      <td>96.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "      <td>119.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>KY</td>\n",
       "      <td>21123</td>\n",
       "      <td>Larue County, Kentucky</td>\n",
       "      <td>6367.0</td>\n",
       "      <td>75.373017</td>\n",
       "      <td>20.072248</td>\n",
       "      <td>67.852186</td>\n",
       "      <td>67.222402</td>\n",
       "      <td>30.065926</td>\n",
       "      <td>30.964714</td>\n",
       "      <td>...</td>\n",
       "      <td>92.85</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.10</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.075</td>\n",
       "      <td>47.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NC</td>\n",
       "      <td>37021</td>\n",
       "      <td>Buncombe County, North Carolina</td>\n",
       "      <td>134507.0</td>\n",
       "      <td>41.142097</td>\n",
       "      <td>55.712342</td>\n",
       "      <td>42.836894</td>\n",
       "      <td>42.403974</td>\n",
       "      <td>55.307136</td>\n",
       "      <td>56.315683</td>\n",
       "      <td>...</td>\n",
       "      <td>85.20</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.075</td>\n",
       "      <td>259.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State   Fips                           County     Votes  Republicans 2016  \\\n",
       "0    MN  27017        Carlton County, Minnesota   18059.0         45.185226   \n",
       "1    KS  20127            Morris County, Kansas    2568.0         69.704050   \n",
       "2    OK  40107        Okfuskee County, Oklahoma    3933.0         70.963641   \n",
       "3    MT  30085        Roosevelt County, Montana    3502.0         49.171902   \n",
       "4    NY  36055          Monroe County, New York  320164.0         40.251559   \n",
       "5    VA  51117     Mecklenburg County, Virginia   15177.0         54.576003   \n",
       "6    GA  13143         Haralson County, Georgia   11317.0         84.642573   \n",
       "7    ME  23017             Oxford County, Maine   31094.0         52.145108   \n",
       "8    KY  21123           Larue County, Kentucky    6367.0         75.373017   \n",
       "9    NC  37021  Buncombe County, North Carolina  134507.0         41.142097   \n",
       "\n",
       "   Democrats 2016  Republicans 2012  Republicans 2008  Democrats 2012  \\\n",
       "0       46.846448         35.723584         35.497859       61.775873   \n",
       "1       22.819315         69.203747         65.997888       28.024980   \n",
       "2       23.976608         65.023670         64.103808       34.976330   \n",
       "3       42.946887         41.230937         35.468336       56.808279   \n",
       "4       54.366824         39.951110         40.474828       57.966886   \n",
       "5       43.295777         52.881873         51.829996       45.904358   \n",
       "6       13.024653         81.399383         78.021087       17.241712   \n",
       "7       39.145816         40.774983         40.641390       55.506458   \n",
       "8       20.072248         67.852186         67.222402       30.065926   \n",
       "9       55.712342         42.836894         42.403974       55.307136   \n",
       "\n",
       "   Democrats 2008  ...  White  Black  Hispanic  Asian  Amerindian  Other Race  \\\n",
       "0       62.339422  ...  89.50   1.35      1.40   0.55        5.40        1.90   \n",
       "1       31.925378  ...  94.20   0.20      3.65   0.55        0.60        0.80   \n",
       "2       35.896192  ...  64.00   9.05      2.60   0.05       15.95        8.25   \n",
       "3       61.738502  ...  36.00   0.05      1.10   0.40       53.55        8.90   \n",
       "4       58.180987  ...  74.25  14.10      6.60   3.00        0.20        1.80   \n",
       "5       47.255006  ...  58.95  36.95      2.30   0.65        0.10        1.05   \n",
       "6       20.257727  ...  91.50   4.95      1.15   0.35        0.30        1.80   \n",
       "7       56.682464  ...  96.55   0.40      0.95   0.50        0.40        1.25   \n",
       "8       30.964714  ...  92.85   3.45      2.15   0.15        0.35        1.10   \n",
       "9       56.315683  ...  85.20   6.60      5.10   1.00        0.30        1.80   \n",
       "\n",
       "   Median Age  Uninsured  Unemployment  Violent crime  \n",
       "0        40.1      0.112         0.071         124.41  \n",
       "1        45.9      0.148         0.066         178.58  \n",
       "2        40.3      0.246         0.072         246.62  \n",
       "3        32.0      0.264         0.074         314.33  \n",
       "4        38.1      0.101         0.080         363.42  \n",
       "5        45.1      0.187         0.098         193.67  \n",
       "6        38.0      0.204         0.095         522.03  \n",
       "7        43.6      0.138         0.091         119.42  \n",
       "8        39.1      0.185         0.075          47.32  \n",
       "9        40.6      0.201         0.075         259.20  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from csv file\n",
    "col_names = []\n",
    "for i in range(33):\n",
    "    if i == 0:\n",
    "        col_names.append('State')\n",
    "    if i == 1:\n",
    "        col_names.append('Fips')\n",
    "    if i == 2:\n",
    "        col_names.append('County')\n",
    "    if i == 3:\n",
    "        col_names.append('Votes')\n",
    "    if i == 4:\n",
    "        col_names.append('Republicans 2016')\n",
    "    if i == 5:\n",
    "        col_names.append('Democrats 2016')\n",
    "    if i == 6:\n",
    "        col_names.append('Republicans 2012')\n",
    "    if i == 7:\n",
    "        col_names.append('Republicans 2008')\n",
    "    if i == 8:\n",
    "        col_names.append('Democrats 2012')\n",
    "    if i == 9:\n",
    "        col_names.append('Democrats 2008')\n",
    "    if i == 10:\n",
    "        col_names.append('Less Than High School Diploma')\n",
    "    if i == 11:\n",
    "        col_names.append('At Least High School Diploma')\n",
    "    if i == 12:\n",
    "        col_names.append('At Least Bachelors Degree')\n",
    "    if i == 13:\n",
    "        col_names.append('Graduate Degree')\n",
    "    if i == 14:\n",
    "        col_names.append('Median Earnings 2010')\n",
    "    if i == 15:\n",
    "        col_names.append('Total Population')\n",
    "    if i == 16:\n",
    "        col_names.append('Poverty Rate below federal poverty threshold')\n",
    "    if i == 17:\n",
    "        col_names.append('Management professional and related occupations')\n",
    "    if i == 18:\n",
    "        col_names.append('Service occupations')\n",
    "    if i == 19:\n",
    "        col_names.append('Sales and office occupations')\n",
    "    if i == 20:\n",
    "        col_names.append('Farming fishing and forestry occupations')\n",
    "    if i == 21:\n",
    "        col_names.append('Construction extraction maintenance and repair occupations')\n",
    "    if i == 22:\n",
    "        col_names.append('Production transportation and material moving occupations')\n",
    "    if i == 23:\n",
    "        col_names.append('White')\n",
    "    if i == 24:\n",
    "        col_names.append('Black')\n",
    "    if i == 25:\n",
    "        col_names.append('Hispanic')\n",
    "    if i == 26:\n",
    "        col_names.append('Asian')\n",
    "    if i == 27:\n",
    "        col_names.append('Amerindian')\n",
    "    if i == 28:\n",
    "        col_names.append('Other Race')\n",
    "    if i == 29:\n",
    "        col_names.append('Median Age')\n",
    "    if i == 30:\n",
    "        col_names.append('Uninsured')\n",
    "    if i == 31:\n",
    "        col_names.append('Unemployment')\n",
    "    if i == 32:\n",
    "        col_names.append('Violent crime')\n",
    "        \n",
    "data = pd.read_csv(\"2016_election_dataset.csv\", names = col_names, index_col=False)\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling the Data\n",
    "\n",
    "Each county is labeled 0 for Republican or 1 for Democrat based on which party had a higher voting percentage in 2016. After these labels are added, the 2016 Democratic and Republican voting percentages are then removed. This is because when we are given a particular county with certain characteristics that we want to predict the political affiliation of, those percentages won't be known.\n",
    "\n",
    "## Cleaning the Data\n",
    "\n",
    "For counties that are missing information in any of the features selected (particularly a few lowly populated counties in Alaska that are too small to have information on all of these fields), we have decided to drop these records from the dataset (List wise deletion). Only a few records have to be dropped under this scenario, and we still have more than enough records to build an accurate and coherent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Fips</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>Democrats 2012</th>\n",
       "      <th>Democrats 2008</th>\n",
       "      <th>Less Than High School Diploma</th>\n",
       "      <th>At Least High School Diploma</th>\n",
       "      <th>At Least Bachelors Degree</th>\n",
       "      <th>...</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Amerindian</th>\n",
       "      <th>Other Race</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "      <th>Party Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27017</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>61.775873</td>\n",
       "      <td>62.339422</td>\n",
       "      <td>9.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20127</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>28.024980</td>\n",
       "      <td>31.925378</td>\n",
       "      <td>9.9</td>\n",
       "      <td>90.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40107</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>34.976330</td>\n",
       "      <td>35.896192</td>\n",
       "      <td>21.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>9.05</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.95</td>\n",
       "      <td>8.25</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30085</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>56.808279</td>\n",
       "      <td>61.738502</td>\n",
       "      <td>10.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>53.55</td>\n",
       "      <td>8.90</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36055</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>57.966886</td>\n",
       "      <td>58.180987</td>\n",
       "      <td>11.6</td>\n",
       "      <td>88.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51117</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>52.881873</td>\n",
       "      <td>51.829996</td>\n",
       "      <td>45.904358</td>\n",
       "      <td>47.255006</td>\n",
       "      <td>24.8</td>\n",
       "      <td>75.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>36.95</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.05</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.098</td>\n",
       "      <td>193.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13143</td>\n",
       "      <td>11317.0</td>\n",
       "      <td>81.399383</td>\n",
       "      <td>78.021087</td>\n",
       "      <td>17.241712</td>\n",
       "      <td>20.257727</td>\n",
       "      <td>30.4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.095</td>\n",
       "      <td>522.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23017</td>\n",
       "      <td>31094.0</td>\n",
       "      <td>40.774983</td>\n",
       "      <td>40.641390</td>\n",
       "      <td>55.506458</td>\n",
       "      <td>56.682464</td>\n",
       "      <td>12.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "      <td>119.42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21123</td>\n",
       "      <td>6367.0</td>\n",
       "      <td>67.852186</td>\n",
       "      <td>67.222402</td>\n",
       "      <td>30.065926</td>\n",
       "      <td>30.964714</td>\n",
       "      <td>23.2</td>\n",
       "      <td>76.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.10</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.075</td>\n",
       "      <td>47.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37021</td>\n",
       "      <td>134507.0</td>\n",
       "      <td>42.836894</td>\n",
       "      <td>42.403974</td>\n",
       "      <td>55.307136</td>\n",
       "      <td>56.315683</td>\n",
       "      <td>12.8</td>\n",
       "      <td>87.2</td>\n",
       "      <td>31.2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.075</td>\n",
       "      <td>259.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Fips     Votes  Republicans 2012  Republicans 2008  Democrats 2012  \\\n",
       "0   26.0  27017   18059.0         35.723584         35.497859       61.775873   \n",
       "1   19.0  20127    2568.0         69.203747         65.997888       28.024980   \n",
       "2   41.0  40107    3933.0         65.023670         64.103808       34.976330   \n",
       "3   30.0  30085    3502.0         41.230937         35.468336       56.808279   \n",
       "4   39.0  36055  320164.0         39.951110         40.474828       57.966886   \n",
       "5   51.0  51117   15177.0         52.881873         51.829996       45.904358   \n",
       "6   12.0  13143   11317.0         81.399383         78.021087       17.241712   \n",
       "7   24.0  23017   31094.0         40.774983         40.641390       55.506458   \n",
       "8   20.0  21123    6367.0         67.852186         67.222402       30.065926   \n",
       "9   32.0  37021  134507.0         42.836894         42.403974       55.307136   \n",
       "\n",
       "   Democrats 2008  Less Than High School Diploma  \\\n",
       "0       62.339422                            9.7   \n",
       "1       31.925378                            9.9   \n",
       "2       35.896192                           21.2   \n",
       "3       61.738502                           10.9   \n",
       "4       58.180987                           11.6   \n",
       "5       47.255006                           24.8   \n",
       "6       20.257727                           30.4   \n",
       "7       56.682464                           12.5   \n",
       "8       30.964714                           23.2   \n",
       "9       56.315683                           12.8   \n",
       "\n",
       "   At Least High School Diploma  At Least Bachelors Degree  ...  Black  \\\n",
       "0                          90.3                       21.4  ...   1.35   \n",
       "1                          90.1                       16.6  ...   0.20   \n",
       "2                          78.8                       10.9  ...   9.05   \n",
       "3                          89.1                       17.3  ...   0.05   \n",
       "4                          88.4                       34.8  ...  14.10   \n",
       "5                          75.2                       13.4  ...  36.95   \n",
       "6                          69.6                       11.0  ...   4.95   \n",
       "7                          87.5                       18.5  ...   0.40   \n",
       "8                          76.8                       12.1  ...   3.45   \n",
       "9                          87.2                       31.2  ...   6.60   \n",
       "\n",
       "   Hispanic  Asian  Amerindian  Other Race  Median Age  Uninsured  \\\n",
       "0      1.40   0.55        5.40        1.90        40.1      0.112   \n",
       "1      3.65   0.55        0.60        0.80        45.9      0.148   \n",
       "2      2.60   0.05       15.95        8.25        40.3      0.246   \n",
       "3      1.10   0.40       53.55        8.90        32.0      0.264   \n",
       "4      6.60   3.00        0.20        1.80        38.1      0.101   \n",
       "5      2.30   0.65        0.10        1.05        45.1      0.187   \n",
       "6      1.15   0.35        0.30        1.80        38.0      0.204   \n",
       "7      0.95   0.50        0.40        1.25        43.6      0.138   \n",
       "8      2.15   0.15        0.35        1.10        39.1      0.185   \n",
       "9      5.10   1.00        0.30        1.80        40.6      0.201   \n",
       "\n",
       "   Unemployment  Violent crime  Party Label  \n",
       "0         0.071         124.41          1.0  \n",
       "1         0.066         178.58          0.0  \n",
       "2         0.072         246.62          0.0  \n",
       "3         0.074         314.33          0.0  \n",
       "4         0.080         363.42          1.0  \n",
       "5         0.098         193.67          0.0  \n",
       "6         0.095         522.03          0.0  \n",
       "7         0.091         119.42          0.0  \n",
       "8         0.075          47.32          0.0  \n",
       "9         0.075         259.20          1.0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Republican is 0, Democrat is 1\n",
    "def label_party (row):\n",
    "    if row['Republicans 2016'] > row['Democrats 2016']:\n",
    "        return 0\n",
    "    if row['Republicans 2016'] < row['Democrats 2016']:\n",
    "        return 1\n",
    "    if row['Republicans 2016'] == row['Democrats 2016']:\n",
    "        return None\n",
    "    \n",
    "def convertToNumber (s):\n",
    "    return int.from_bytes(s.encode(), 'little')\n",
    "\n",
    "# add label\n",
    "data['Party Label'] = data.apply (lambda row: label_party(row), axis=1)\n",
    "\n",
    "states = {\n",
    "        'AK': 1,'AL': 2,'AR': 3,'AS': 4,'AZ': 5,'CA': 6,'CO': 7,'CT': 8,'DC': 9,'DE': 10,'FL': 11,'GA': 12,'GU': 13,'HI': 14,\n",
    "        'IA': 15,'ID': 16,'IL': 17,'IN': 18,'KS': 19,'KY': 20,'LA': 21,'MA': 22,'MD': 23,'ME': 24,'MI': 25,'MN': 26,'MO': 27,\n",
    "        'MP': 28,'MS': 29,'MT': 30,'NA': 31,'NC': 32,'ND': 33,'NE': 34,'NH': 35,'NJ': 36,'NM': 37,'NV': 38,'NY': 39,'OH': 40,\n",
    "        'OK': 41,'OR': 42,'PA': 43,'PR': 44,'RI': 45,'SC': 46,'SD': 47,'TN': 48,'TX': 49,'UT': 50,'VA': 51,'VI': 52, 'VT': 53,\n",
    "        'WA': 54,'WI': 55,'WV': 56,'WY': 57\n",
    "}\n",
    "data['State']=data['State'].map(states)\n",
    "\n",
    "data = data.drop('County', axis=1)\n",
    "data = data.drop('Republicans 2016', axis=1)\n",
    "data = data.drop('Democrats 2016', axis=1)\n",
    "\n",
    "#just some test, accuracy drops to 89%, so not much really.\n",
    "# data = data.drop('Republicans 2012', axis=1)\n",
    "# data = data.drop('Democrats 2012', axis=1)\n",
    "# data = data.drop('Republicans 2008', axis=1)\n",
    "# data = data.drop('Democrats 2008', axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (2944, 30)\n",
      "Labels shape: (2944,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Fips</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>Democrats 2012</th>\n",
       "      <th>Democrats 2008</th>\n",
       "      <th>Less Than High School Diploma</th>\n",
       "      <th>At Least High School Diploma</th>\n",
       "      <th>At Least Bachelors Degree</th>\n",
       "      <th>...</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Amerindian</th>\n",
       "      <th>Other Race</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27017</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>61.775873</td>\n",
       "      <td>62.339422</td>\n",
       "      <td>9.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>89.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20127</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>28.024980</td>\n",
       "      <td>31.925378</td>\n",
       "      <td>9.9</td>\n",
       "      <td>90.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>...</td>\n",
       "      <td>94.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40107</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>34.976330</td>\n",
       "      <td>35.896192</td>\n",
       "      <td>21.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>64.00</td>\n",
       "      <td>9.05</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.95</td>\n",
       "      <td>8.25</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30085</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>56.808279</td>\n",
       "      <td>61.738502</td>\n",
       "      <td>10.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>53.55</td>\n",
       "      <td>8.90</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36055</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>57.966886</td>\n",
       "      <td>58.180987</td>\n",
       "      <td>11.6</td>\n",
       "      <td>88.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>74.25</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.60</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Fips     Votes  Republicans 2012  Republicans 2008  Democrats 2012  \\\n",
       "0   26.0  27017   18059.0         35.723584         35.497859       61.775873   \n",
       "1   19.0  20127    2568.0         69.203747         65.997888       28.024980   \n",
       "2   41.0  40107    3933.0         65.023670         64.103808       34.976330   \n",
       "3   30.0  30085    3502.0         41.230937         35.468336       56.808279   \n",
       "4   39.0  36055  320164.0         39.951110         40.474828       57.966886   \n",
       "\n",
       "   Democrats 2008  Less Than High School Diploma  \\\n",
       "0       62.339422                            9.7   \n",
       "1       31.925378                            9.9   \n",
       "2       35.896192                           21.2   \n",
       "3       61.738502                           10.9   \n",
       "4       58.180987                           11.6   \n",
       "\n",
       "   At Least High School Diploma  At Least Bachelors Degree  ...  White  Black  \\\n",
       "0                          90.3                       21.4  ...  89.50   1.35   \n",
       "1                          90.1                       16.6  ...  94.20   0.20   \n",
       "2                          78.8                       10.9  ...  64.00   9.05   \n",
       "3                          89.1                       17.3  ...  36.00   0.05   \n",
       "4                          88.4                       34.8  ...  74.25  14.10   \n",
       "\n",
       "   Hispanic  Asian  Amerindian  Other Race  Median Age  Uninsured  \\\n",
       "0      1.40   0.55        5.40        1.90        40.1      0.112   \n",
       "1      3.65   0.55        0.60        0.80        45.9      0.148   \n",
       "2      2.60   0.05       15.95        8.25        40.3      0.246   \n",
       "3      1.10   0.40       53.55        8.90        32.0      0.264   \n",
       "4      6.60   3.00        0.20        1.80        38.1      0.101   \n",
       "\n",
       "   Unemployment  Violent crime  \n",
       "0         0.071         124.41  \n",
       "1         0.066         178.58  \n",
       "2         0.072         246.62  \n",
       "3         0.074         314.33  \n",
       "4         0.080         363.42  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the Data\n",
    "\n",
    "In attempting to build the best model possible to classify our records, we will first test several different classification algorithms on our data and assess the performance of each of them. We will assess each of these algorithms on how accurate they are, and how well they handle class imbalance, and display the results of each of those algorithms. Below, we discuss these two meaures in more detail.\n",
    "\n",
    "### 1) Accuracy\n",
    "\n",
    "Each algorithm will be tested on the data using K-Fold Cross Validation with 10 folds. In the first iteration, the first tenth of the data set will serve as the testing data and have the labels removed. The rest of the dataset will serve as the training data which will be used to build the algorithm. Once the algorithm is built, the testing records will be fed into the algorithm and classified. The alrogithm's classification of those testing records will be compared to the actual labels of those testing records to determine the accuracy of that iteration. In the second iteration, the second tenth of the data set will serve as the testing data while the rest serves as the training data. And so forth until all 10 folds are completed. The accuracy of that algorithm will be the average accuracy among those 10 folds.\n",
    "\n",
    "### 2) Class Imbalance\n",
    "\n",
    "Our dataset contains significantly more Republican than Democratic records given that the Democratic population tends to be more concentrated in urban areas. If our model were to be making mostly Republican predictions and have thus a high accuracy rate, we would want to know if this is because the model can properly distinguish what a Republican county looks like or the model is simply giving Republican labels most of the time without making that distinction. Creating a confusion matrix would be a more effective way to analyze the performance of a model instead of simplying looking at it's accuracy rate.\n",
    "\n",
    "In the matrix, the top left value is the number of True Positive Classifications (number of records classified Republican that were actually Republican. The Bottom left is the number of False Positive Classifications (number of records classified Republican that were actually Democratic). The top right is the number of False Negative Classifications (number of records classified Democratic that were actually Republican). And the bottom right is the nuumber of True Negative Classifications (number of records classified Democratic that were actually Democratic).\n",
    "\n",
    "Thus, in this scenario, we are particulary interested in achieveing a low rate of False Positive Classifications to indicate that the algorithm isn't making mostly Republican predictions simply because the majority class is Republican.\n",
    "\n",
    "Another way to analyze the algorithms performance under this Class Imbalance is calculating Precision and Recall. Precision is the probability that given a Repbulican classification, how likely is it to be correct. And Recall is the probability that given a Republican record, will it be classified as such. In this scenario, we are particularly interested in a high recall rate. The F-measure is also calculated which is a combination of both the precision and recall metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 94.29436181252161\n",
      "[[2411   66]\n",
      " [ 102  365]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97      2477\n",
      "         1.0       0.85      0.78      0.81       467\n",
      "\n",
      "    accuracy                           0.94      2944\n",
      "   macro avg       0.90      0.88      0.89      2944\n",
      "weighted avg       0.94      0.94      0.94      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Naive Bayes Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier: 96.67220108382337\n",
      "[[2433   44]\n",
      " [  53  414]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2477\n",
      "         1.0       0.90      0.89      0.90       467\n",
      "\n",
      "    accuracy                           0.97      2944\n",
      "   macro avg       0.94      0.93      0.94      2944\n",
      "weighted avg       0.97      0.97      0.97      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Decision Tree Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imbalance\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier: 86.82013144240747\n",
      "[[2404   73]\n",
      " [ 315  152]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.93      2477\n",
      "         1.0       0.68      0.33      0.44       467\n",
      "\n",
      "    accuracy                           0.87      2944\n",
      "   macro avg       0.78      0.65      0.68      2944\n",
      "weighted avg       0.85      0.87      0.85      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 20)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.1657484725639 \n",
      "\n",
      "[[2404   73]\n",
      " [ 315  152]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.93      2477\n",
      "         1.0       0.68      0.33      0.44       467\n",
      "\n",
      "    accuracy                           0.87      2944\n",
      "   macro avg       0.78      0.65      0.68      2944\n",
      "weighted avg       0.85      0.87      0.85      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "\n",
    "#THIS SHOULD ALREADY BE DONE   \n",
    "# data_Y = data['Party Label']\n",
    "# data_X = data.drop(['Party Label'],axis=1)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.20)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "scaler = StandardScaler()\n",
    "svc = SVC(gamma='auto')\n",
    "\n",
    "pipeline_svm = Pipeline([('scaler', scaler), ('pca', pca), ('svc', svc)])\n",
    "param_grid = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "y_preds = cross_val_predict(pipeline_svm, features_test, labels_test, cv=10) \n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.23360243927792 \n",
      "\n",
      "[[2404   73]\n",
      " [ 315  152]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.93      2477\n",
      "         1.0       0.68      0.33      0.44       467\n",
      "\n",
      "    accuracy                           0.87      2944\n",
      "   macro avg       0.78      0.65      0.68      2944\n",
      "weighted avg       0.85      0.87      0.85      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_class = MLPClassifier()\n",
    "pipeline_nn = Pipeline([('scaler', scaler), ('mlp_classifier', mlp_class)])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp_classifier__hidden_layer_sizes': list(range(30, 60, 10)),\n",
    "    'mlp_classifier__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_nn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature Engineering is the process of creating new features in our dataset from a combination of exisiting features. Feature Engineering may improve the performance of the model by creating a feature that is more inditicative of political affiliation than exisiting features, reducing the total number of features that the algorithm has to work with, or a combination of both of these factors.\n",
    "\n",
    "One feature we added was the percentage of residents in Professional industries by adding the percentage of residents in both management and sales occuptions. Residents working in both of these types of professions tend to be of similar economic status. We then deleted the two individual columns in exchange for this new addition, reducing the total number of features used by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Fips</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>Democrats 2012</th>\n",
       "      <th>Democrats 2008</th>\n",
       "      <th>Less Than High School Diploma</th>\n",
       "      <th>At Least High School Diploma</th>\n",
       "      <th>At Least Bachelors Degree</th>\n",
       "      <th>...</th>\n",
       "      <th>White</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "      <th>Voter Turnout</th>\n",
       "      <th>Minority</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Manufacturing</th>\n",
       "      <th>Party Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27017</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>61.775873</td>\n",
       "      <td>62.339422</td>\n",
       "      <td>9.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>89.50</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "      <td>52.148426</td>\n",
       "      <td>10.60</td>\n",
       "      <td>53.40</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20127</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>28.024980</td>\n",
       "      <td>31.925378</td>\n",
       "      <td>9.9</td>\n",
       "      <td>90.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>...</td>\n",
       "      <td>94.20</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "      <td>43.203230</td>\n",
       "      <td>5.80</td>\n",
       "      <td>49.35</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40107</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>34.976330</td>\n",
       "      <td>35.896192</td>\n",
       "      <td>21.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>64.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "      <td>33.724919</td>\n",
       "      <td>35.90</td>\n",
       "      <td>50.30</td>\n",
       "      <td>28.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30085</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>56.808279</td>\n",
       "      <td>61.738502</td>\n",
       "      <td>10.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "      <td>33.907823</td>\n",
       "      <td>64.00</td>\n",
       "      <td>59.50</td>\n",
       "      <td>18.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36055</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>57.966886</td>\n",
       "      <td>58.180987</td>\n",
       "      <td>11.6</td>\n",
       "      <td>88.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>74.25</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "      <td>43.383714</td>\n",
       "      <td>25.70</td>\n",
       "      <td>66.50</td>\n",
       "      <td>17.35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51117</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>52.881873</td>\n",
       "      <td>51.829996</td>\n",
       "      <td>45.904358</td>\n",
       "      <td>47.255006</td>\n",
       "      <td>24.8</td>\n",
       "      <td>75.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>58.95</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.098</td>\n",
       "      <td>193.67</td>\n",
       "      <td>46.904843</td>\n",
       "      <td>41.05</td>\n",
       "      <td>52.45</td>\n",
       "      <td>30.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13143</td>\n",
       "      <td>11317.0</td>\n",
       "      <td>81.399383</td>\n",
       "      <td>78.021087</td>\n",
       "      <td>17.241712</td>\n",
       "      <td>20.257727</td>\n",
       "      <td>30.4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.095</td>\n",
       "      <td>522.03</td>\n",
       "      <td>39.474694</td>\n",
       "      <td>8.55</td>\n",
       "      <td>49.50</td>\n",
       "      <td>35.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23017</td>\n",
       "      <td>31094.0</td>\n",
       "      <td>40.774983</td>\n",
       "      <td>40.641390</td>\n",
       "      <td>55.506458</td>\n",
       "      <td>56.682464</td>\n",
       "      <td>12.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>...</td>\n",
       "      <td>96.55</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "      <td>119.42</td>\n",
       "      <td>54.433416</td>\n",
       "      <td>3.50</td>\n",
       "      <td>47.20</td>\n",
       "      <td>32.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21123</td>\n",
       "      <td>6367.0</td>\n",
       "      <td>67.852186</td>\n",
       "      <td>67.222402</td>\n",
       "      <td>30.065926</td>\n",
       "      <td>30.964714</td>\n",
       "      <td>23.2</td>\n",
       "      <td>76.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.85</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.075</td>\n",
       "      <td>47.32</td>\n",
       "      <td>45.851937</td>\n",
       "      <td>7.20</td>\n",
       "      <td>45.35</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37021</td>\n",
       "      <td>134507.0</td>\n",
       "      <td>42.836894</td>\n",
       "      <td>42.403974</td>\n",
       "      <td>55.307136</td>\n",
       "      <td>56.315683</td>\n",
       "      <td>12.8</td>\n",
       "      <td>87.2</td>\n",
       "      <td>31.2</td>\n",
       "      <td>...</td>\n",
       "      <td>85.20</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.075</td>\n",
       "      <td>259.20</td>\n",
       "      <td>57.953924</td>\n",
       "      <td>14.80</td>\n",
       "      <td>59.75</td>\n",
       "      <td>21.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Fips     Votes  Republicans 2012  Republicans 2008  Democrats 2012  \\\n",
       "0   26.0  27017   18059.0         35.723584         35.497859       61.775873   \n",
       "1   19.0  20127    2568.0         69.203747         65.997888       28.024980   \n",
       "2   41.0  40107    3933.0         65.023670         64.103808       34.976330   \n",
       "3   30.0  30085    3502.0         41.230937         35.468336       56.808279   \n",
       "4   39.0  36055  320164.0         39.951110         40.474828       57.966886   \n",
       "5   51.0  51117   15177.0         52.881873         51.829996       45.904358   \n",
       "6   12.0  13143   11317.0         81.399383         78.021087       17.241712   \n",
       "7   24.0  23017   31094.0         40.774983         40.641390       55.506458   \n",
       "8   20.0  21123    6367.0         67.852186         67.222402       30.065926   \n",
       "9   32.0  37021  134507.0         42.836894         42.403974       55.307136   \n",
       "\n",
       "   Democrats 2008  Less Than High School Diploma  \\\n",
       "0       62.339422                            9.7   \n",
       "1       31.925378                            9.9   \n",
       "2       35.896192                           21.2   \n",
       "3       61.738502                           10.9   \n",
       "4       58.180987                           11.6   \n",
       "5       47.255006                           24.8   \n",
       "6       20.257727                           30.4   \n",
       "7       56.682464                           12.5   \n",
       "8       30.964714                           23.2   \n",
       "9       56.315683                           12.8   \n",
       "\n",
       "   At Least High School Diploma  At Least Bachelors Degree  ...  White  \\\n",
       "0                          90.3                       21.4  ...  89.50   \n",
       "1                          90.1                       16.6  ...  94.20   \n",
       "2                          78.8                       10.9  ...  64.00   \n",
       "3                          89.1                       17.3  ...  36.00   \n",
       "4                          88.4                       34.8  ...  74.25   \n",
       "5                          75.2                       13.4  ...  58.95   \n",
       "6                          69.6                       11.0  ...  91.50   \n",
       "7                          87.5                       18.5  ...  96.55   \n",
       "8                          76.8                       12.1  ...  92.85   \n",
       "9                          87.2                       31.2  ...  85.20   \n",
       "\n",
       "   Median Age  Uninsured  Unemployment  Violent crime  Voter Turnout  \\\n",
       "0        40.1      0.112         0.071         124.41      52.148426   \n",
       "1        45.9      0.148         0.066         178.58      43.203230   \n",
       "2        40.3      0.246         0.072         246.62      33.724919   \n",
       "3        32.0      0.264         0.074         314.33      33.907823   \n",
       "4        38.1      0.101         0.080         363.42      43.383714   \n",
       "5        45.1      0.187         0.098         193.67      46.904843   \n",
       "6        38.0      0.204         0.095         522.03      39.474694   \n",
       "7        43.6      0.138         0.091         119.42      54.433416   \n",
       "8        39.1      0.185         0.075          47.32      45.851937   \n",
       "9        40.6      0.201         0.075         259.20      57.953924   \n",
       "\n",
       "   Minority  Professional  Manufacturing  Party Label  \n",
       "0     10.60         53.40          26.00          1.0  \n",
       "1      5.80         49.35          37.75          0.0  \n",
       "2     35.90         50.30          28.55          0.0  \n",
       "3     64.00         59.50          18.75          0.0  \n",
       "4     25.70         66.50          17.35          1.0  \n",
       "5     41.05         52.45          30.75          0.0  \n",
       "6      8.55         49.50          35.30          0.0  \n",
       "7      3.50         47.20          32.80          0.0  \n",
       "8      7.20         45.35          40.80          0.0  \n",
       "9     14.80         59.75          21.75          1.0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def voter_turnout (row):\n",
    "    return (row['Votes'] / row['Total Population']) * 100\n",
    "\n",
    "def minority(row):\n",
    "    return (row['Black'] + row['Hispanic'] + row['Asian'] + row['Amerindian'] + row['Other Race'])\n",
    "\n",
    "def professional(row):\n",
    "    return (row['Management professional and related occupations'] + row['Sales and office occupations'])\n",
    "    \n",
    "def manufacturing(row):\n",
    "    return (row['Farming fishing and forestry occupations'] + row['Construction extraction maintenance and repair occupations'] + row['Production transportation and material moving occupations'])\n",
    "    \n",
    "data1 = data.pop('Party Label')    \n",
    "    \n",
    "data['Voter Turnout'] = data.apply (lambda row: voter_turnout(row), axis=1)\n",
    "data['Minority'] = data.apply (lambda row: minority(row), axis=1)\n",
    "data['Professional'] = data.apply (lambda row: professional(row), axis=1)\n",
    "data['Manufacturing'] = data.apply (lambda row: manufacturing(row), axis=1)\n",
    "\n",
    "data = data.drop('Black', axis=1)\n",
    "data = data.drop('Hispanic', axis=1)\n",
    "data = data.drop('Asian', axis=1)\n",
    "data = data.drop('Amerindian', axis=1)\n",
    "data = data.drop('Other Race', axis=1)\n",
    "data = data.drop('Management professional and related occupations', axis=1)\n",
    "data = data.drop('Sales and office occupations', axis=1)\n",
    "data = data.drop('Farming fishing and forestry occupations', axis=1)\n",
    "data = data.drop('Construction extraction maintenance and repair occupations', axis=1)\n",
    "data = data.drop('Production transportation and material moving occupations', axis=1)\n",
    "\n",
    "data['Party Label'] = data1\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (2944, 24)\n",
      "Labels shape: (2944,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Fips</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>Democrats 2012</th>\n",
       "      <th>Democrats 2008</th>\n",
       "      <th>Less Than High School Diploma</th>\n",
       "      <th>At Least High School Diploma</th>\n",
       "      <th>At Least Bachelors Degree</th>\n",
       "      <th>...</th>\n",
       "      <th>Service occupations</th>\n",
       "      <th>White</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "      <th>Voter Turnout</th>\n",
       "      <th>Minority</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Manufacturing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27017</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>61.775873</td>\n",
       "      <td>62.339422</td>\n",
       "      <td>9.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.55</td>\n",
       "      <td>89.50</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "      <td>52.148426</td>\n",
       "      <td>10.6</td>\n",
       "      <td>53.40</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20127</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>28.024980</td>\n",
       "      <td>31.925378</td>\n",
       "      <td>9.9</td>\n",
       "      <td>90.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.95</td>\n",
       "      <td>94.20</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "      <td>43.203230</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49.35</td>\n",
       "      <td>37.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40107</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>34.976330</td>\n",
       "      <td>35.896192</td>\n",
       "      <td>21.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21.15</td>\n",
       "      <td>64.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "      <td>33.724919</td>\n",
       "      <td>35.9</td>\n",
       "      <td>50.30</td>\n",
       "      <td>28.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30085</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>56.808279</td>\n",
       "      <td>61.738502</td>\n",
       "      <td>10.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>...</td>\n",
       "      <td>21.75</td>\n",
       "      <td>36.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "      <td>33.907823</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.50</td>\n",
       "      <td>18.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36055</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>57.966886</td>\n",
       "      <td>58.180987</td>\n",
       "      <td>11.6</td>\n",
       "      <td>88.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>16.15</td>\n",
       "      <td>74.25</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "      <td>43.383714</td>\n",
       "      <td>25.7</td>\n",
       "      <td>66.50</td>\n",
       "      <td>17.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Fips     Votes  Republicans 2012  Republicans 2008  Democrats 2012  \\\n",
       "0   26.0  27017   18059.0         35.723584         35.497859       61.775873   \n",
       "1   19.0  20127    2568.0         69.203747         65.997888       28.024980   \n",
       "2   41.0  40107    3933.0         65.023670         64.103808       34.976330   \n",
       "3   30.0  30085    3502.0         41.230937         35.468336       56.808279   \n",
       "4   39.0  36055  320164.0         39.951110         40.474828       57.966886   \n",
       "\n",
       "   Democrats 2008  Less Than High School Diploma  \\\n",
       "0       62.339422                            9.7   \n",
       "1       31.925378                            9.9   \n",
       "2       35.896192                           21.2   \n",
       "3       61.738502                           10.9   \n",
       "4       58.180987                           11.6   \n",
       "\n",
       "   At Least High School Diploma  At Least Bachelors Degree  ...  \\\n",
       "0                          90.3                       21.4  ...   \n",
       "1                          90.1                       16.6  ...   \n",
       "2                          78.8                       10.9  ...   \n",
       "3                          89.1                       17.3  ...   \n",
       "4                          88.4                       34.8  ...   \n",
       "\n",
       "   Service occupations  White  Median Age  Uninsured  Unemployment  \\\n",
       "0                20.55  89.50        40.1      0.112         0.071   \n",
       "1                12.95  94.20        45.9      0.148         0.066   \n",
       "2                21.15  64.00        40.3      0.246         0.072   \n",
       "3                21.75  36.00        32.0      0.264         0.074   \n",
       "4                16.15  74.25        38.1      0.101         0.080   \n",
       "\n",
       "   Violent crime  Voter Turnout  Minority  Professional  Manufacturing  \n",
       "0         124.41      52.148426      10.6         53.40          26.00  \n",
       "1         178.58      43.203230       5.8         49.35          37.75  \n",
       "2         246.62      33.724919      35.9         50.30          28.55  \n",
       "3         314.33      33.907823      64.0         59.50          18.75  \n",
       "4         363.42      43.383714      25.7         66.50          17.35  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Classification Algorithms\n",
    "\n",
    "We will now run our classification algorithms again with the new features in our dataset to assess to what degree adding or removing certain attributes will affect the accuracy of classifying our data. We will thus display the accuracy and class imblance for each algorithm under these new conditions. Furthermore, there are potential ways that each individual classification algorithm can be optimized based on their unique characteristics and we will explore that as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier: 94.32814481724894\n",
      "[[2403   74]\n",
      " [  93  374]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97      2477\n",
      "         1.0       0.83      0.80      0.82       467\n",
      "\n",
      "    accuracy                           0.94      2944\n",
      "   macro avg       0.90      0.89      0.89      2944\n",
      "weighted avg       0.94      0.94      0.94      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Naive Bayes Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes has the assumption that all the features in the dataset are indepedent. However, some features are depedent on each other, for example, all the percentages of race will add up to 100%. The following will attempt to remove some features that are dependent on each other to see if it gives a different accuracy. As it turned out, the accuracy decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Republicans 2012</th>\n",
       "      <th>Republicans 2008</th>\n",
       "      <th>At Least High School Diploma</th>\n",
       "      <th>At Least Bachelors Degree</th>\n",
       "      <th>Graduate Degree</th>\n",
       "      <th>Median Earnings 2010</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Poverty Rate below federal poverty threshold</th>\n",
       "      <th>Service occupations</th>\n",
       "      <th>White</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Uninsured</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Violent crime</th>\n",
       "      <th>Manufacturing</th>\n",
       "      <th>Party Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18059.0</td>\n",
       "      <td>35.723584</td>\n",
       "      <td>35.497859</td>\n",
       "      <td>90.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>30427.26762</td>\n",
       "      <td>34630</td>\n",
       "      <td>10.70</td>\n",
       "      <td>20.55</td>\n",
       "      <td>89.50</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.071</td>\n",
       "      <td>124.41</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2568.0</td>\n",
       "      <td>69.203747</td>\n",
       "      <td>65.997888</td>\n",
       "      <td>90.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>25341.94984</td>\n",
       "      <td>5944</td>\n",
       "      <td>11.15</td>\n",
       "      <td>12.95</td>\n",
       "      <td>94.20</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.066</td>\n",
       "      <td>178.58</td>\n",
       "      <td>37.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>65.023670</td>\n",
       "      <td>64.103808</td>\n",
       "      <td>78.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>22072.27842</td>\n",
       "      <td>11662</td>\n",
       "      <td>24.15</td>\n",
       "      <td>21.15</td>\n",
       "      <td>64.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.072</td>\n",
       "      <td>246.62</td>\n",
       "      <td>28.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>41.230937</td>\n",
       "      <td>35.468336</td>\n",
       "      <td>89.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>27894.54699</td>\n",
       "      <td>10328</td>\n",
       "      <td>23.20</td>\n",
       "      <td>21.75</td>\n",
       "      <td>36.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>314.33</td>\n",
       "      <td>18.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>320164.0</td>\n",
       "      <td>39.951110</td>\n",
       "      <td>40.474828</td>\n",
       "      <td>88.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>29746.92032</td>\n",
       "      <td>737982</td>\n",
       "      <td>13.40</td>\n",
       "      <td>16.15</td>\n",
       "      <td>74.25</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.080</td>\n",
       "      <td>363.42</td>\n",
       "      <td>17.35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>52.881873</td>\n",
       "      <td>51.829996</td>\n",
       "      <td>75.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>22376.19207</td>\n",
       "      <td>32357</td>\n",
       "      <td>17.95</td>\n",
       "      <td>16.70</td>\n",
       "      <td>58.95</td>\n",
       "      <td>45.1</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.098</td>\n",
       "      <td>193.67</td>\n",
       "      <td>30.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11317.0</td>\n",
       "      <td>81.399383</td>\n",
       "      <td>78.021087</td>\n",
       "      <td>69.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>25390.72349</td>\n",
       "      <td>28669</td>\n",
       "      <td>19.60</td>\n",
       "      <td>15.20</td>\n",
       "      <td>91.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.095</td>\n",
       "      <td>522.03</td>\n",
       "      <td>35.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31094.0</td>\n",
       "      <td>40.774983</td>\n",
       "      <td>40.641390</td>\n",
       "      <td>87.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>24005.21238</td>\n",
       "      <td>57123</td>\n",
       "      <td>13.40</td>\n",
       "      <td>20.10</td>\n",
       "      <td>96.55</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.091</td>\n",
       "      <td>119.42</td>\n",
       "      <td>32.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6367.0</td>\n",
       "      <td>67.852186</td>\n",
       "      <td>67.222402</td>\n",
       "      <td>76.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>22324.71429</td>\n",
       "      <td>13886</td>\n",
       "      <td>14.55</td>\n",
       "      <td>13.90</td>\n",
       "      <td>92.85</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.075</td>\n",
       "      <td>47.32</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>134507.0</td>\n",
       "      <td>42.836894</td>\n",
       "      <td>42.403974</td>\n",
       "      <td>87.2</td>\n",
       "      <td>31.2</td>\n",
       "      <td>11.1</td>\n",
       "      <td>25470.16032</td>\n",
       "      <td>232093</td>\n",
       "      <td>14.25</td>\n",
       "      <td>18.45</td>\n",
       "      <td>85.20</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.075</td>\n",
       "      <td>259.20</td>\n",
       "      <td>21.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State     Votes  Republicans 2012  Republicans 2008  \\\n",
       "0   26.0   18059.0         35.723584         35.497859   \n",
       "1   19.0    2568.0         69.203747         65.997888   \n",
       "2   41.0    3933.0         65.023670         64.103808   \n",
       "3   30.0    3502.0         41.230937         35.468336   \n",
       "4   39.0  320164.0         39.951110         40.474828   \n",
       "5   51.0   15177.0         52.881873         51.829996   \n",
       "6   12.0   11317.0         81.399383         78.021087   \n",
       "7   24.0   31094.0         40.774983         40.641390   \n",
       "8   20.0    6367.0         67.852186         67.222402   \n",
       "9   32.0  134507.0         42.836894         42.403974   \n",
       "\n",
       "   At Least High School Diploma  At Least Bachelors Degree  Graduate Degree  \\\n",
       "0                          90.3                       21.4              7.2   \n",
       "1                          90.1                       16.6              7.7   \n",
       "2                          78.8                       10.9              3.1   \n",
       "3                          89.1                       17.3              4.7   \n",
       "4                          88.4                       34.8             15.1   \n",
       "5                          75.2                       13.4              4.8   \n",
       "6                          69.6                       11.0              3.2   \n",
       "7                          87.5                       18.5              6.2   \n",
       "8                          76.8                       12.1              4.9   \n",
       "9                          87.2                       31.2             11.1   \n",
       "\n",
       "   Median Earnings 2010  Total Population  \\\n",
       "0           30427.26762             34630   \n",
       "1           25341.94984              5944   \n",
       "2           22072.27842             11662   \n",
       "3           27894.54699             10328   \n",
       "4           29746.92032            737982   \n",
       "5           22376.19207             32357   \n",
       "6           25390.72349             28669   \n",
       "7           24005.21238             57123   \n",
       "8           22324.71429             13886   \n",
       "9           25470.16032            232093   \n",
       "\n",
       "   Poverty Rate below federal poverty threshold  Service occupations  White  \\\n",
       "0                                         10.70                20.55  89.50   \n",
       "1                                         11.15                12.95  94.20   \n",
       "2                                         24.15                21.15  64.00   \n",
       "3                                         23.20                21.75  36.00   \n",
       "4                                         13.40                16.15  74.25   \n",
       "5                                         17.95                16.70  58.95   \n",
       "6                                         19.60                15.20  91.50   \n",
       "7                                         13.40                20.10  96.55   \n",
       "8                                         14.55                13.90  92.85   \n",
       "9                                         14.25                18.45  85.20   \n",
       "\n",
       "   Median Age  Uninsured  Unemployment  Violent crime  Manufacturing  \\\n",
       "0        40.1      0.112         0.071         124.41          26.00   \n",
       "1        45.9      0.148         0.066         178.58          37.75   \n",
       "2        40.3      0.246         0.072         246.62          28.55   \n",
       "3        32.0      0.264         0.074         314.33          18.75   \n",
       "4        38.1      0.101         0.080         363.42          17.35   \n",
       "5        45.1      0.187         0.098         193.67          30.75   \n",
       "6        38.0      0.204         0.095         522.03          35.30   \n",
       "7        43.6      0.138         0.091         119.42          32.80   \n",
       "8        39.1      0.185         0.075          47.32          40.80   \n",
       "9        40.6      0.201         0.075         259.20          21.75   \n",
       "\n",
       "   Party Label  \n",
       "0          1.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          1.0  \n",
       "5          0.0  \n",
       "6          0.0  \n",
       "7          0.0  \n",
       "8          0.0  \n",
       "9          1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('Fips', axis=1)\n",
    "data = data.drop('Democrats 2012', axis=1)\n",
    "data = data.drop('Democrats 2008', axis=1)\n",
    "data = data.drop('Less Than High School Diploma', axis=1)\n",
    "data = data.drop('Minority', axis=1)\n",
    "data = data.drop('Voter Turnout', axis=1)\n",
    "data = data.drop('Professional', axis=1)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (2944, 17)\n",
      "Labels shape: (2944,)\n",
      "Accuracy: 91.84838002997807\n",
      "[[2400   77]\n",
      " [ 163  304]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      2477\n",
      "         1.0       0.80      0.65      0.72       467\n",
      "\n",
      "    accuracy                           0.92      2944\n",
      "   macro avg       0.87      0.81      0.83      2944\n",
      "weighted avg       0.91      0.92      0.92      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "data.head()\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Leon: Run Decision Tree Accuracy & Classification Report with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Leon: Discuss problem with overfitting and using different tree sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Leon: Run Decision Tree Accuracy & Classification Report with some different max tree sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Classifier: 86.4470194857604\n",
      "[[2409   68]\n",
      " [ 331  136]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92      2477\n",
      "         1.0       0.67      0.29      0.41       467\n",
      "\n",
      "    accuracy                           0.86      2944\n",
      "   macro avg       0.77      0.63      0.66      2944\n",
      "weighted avg       0.85      0.86      0.84      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO Tiffany: Run KNN Accuracy & Classification Report with new features\n",
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 15)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbor algorithm is affected by class imbalances - if there is an uneven ratio of one class label to another, it may predict that the majority class is more likely, simply because it has more records. To combat this, we will weight points by the inverse of their distance. In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away. As it so happens, this caused the accuracy to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Weighted KNN Classifier: 86.07263922518159\n",
      "[[2400   77]\n",
      " [ 333  134]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92      2477\n",
      "         1.0       0.64      0.29      0.40       467\n",
      "\n",
      "    accuracy                           0.86      2944\n",
      "   macro avg       0.76      0.63      0.66      2944\n",
      "weighted avg       0.84      0.86      0.84      2944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO Tiffany: Run KNN Accuracy & Classification Report with weighted votes\n",
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 15)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val, weights='distance')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Weighted KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Emily: Run SVM Accuracy & Classification Report with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Emily: Discuss problem with selecting right kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Emily: Run SVM Accuracy & Classification Report with different kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Emily: Run NN Accuracy & Classification Report with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Emily or Leon: Discuss problem with training it correctly and getting stuck at local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Emily or Leon: Run NN Accuracy & Classification with different Hidden Layer Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling\n",
    "\n",
    "TODO Leon: Write an explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogenous Random Forest Ensemble With Decision Trees: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-46c6c4241d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline(steps = [('rfc', RandomForestClassifier())])\n",
    "param_grid = {\n",
    "    'rfc__max_depth': list(range(35, 55)),\n",
    "    'rfc__min_samples_leaf': [8,10,12],\n",
    "    'rfc__max_features': [\"sqrt\", \"log2\"]\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv = 5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterogeneous Stacked Ensemble Using Decision Trees, Naive Bayes, and SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.26485568760611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# creating the different classifiers\n",
    "clf_1 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_2 = GaussianNB()\n",
    "clf_3 = SVC(gamma='auto')\n",
    "\n",
    "estimators = [('dt', clf_1), ('nb', clf_2), ('svm', clf_3)]\n",
    "\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators)\n",
    "acc = clf.fit(features_train, labels_train).score(features_test, labels_test)\n",
    "print(\"Accuracy:\", acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Everyone else: add in your ensembling algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "\n",
    "A ROC Curve illustrates the alrogithm's trade off between its True Positive Rate and True Negative Rate. The higher percentage of the graph area that is under the curve (AUC or Area Under the Curve), the more accurate the algorithm is. An AUC value of 50% indicates that the algorithm is about as good as random guessing, and the algorithm clearly performs well beyond that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "proba = clf.predict_proba(features_test)\n",
    "fpr_result, tpr_result, thresholds = roc_curve(labels_test, proba[:,1])\n",
    "#replace these fpr and tpr with the results of your roc_curve\n",
    "fpr, tpr = fpr_result, tpr_result\n",
    "\n",
    "print(roc_auc_score(labels_test, proba[:,1]))\n",
    "\n",
    "# Do not change this code! This plots the ROC curve.\n",
    "# Just replace the fpr and tpr above with the values from your roc_curve\n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "proba = clf.predict_proba(features_test)\n",
    "fpr_result, tpr_result, thresholds = roc_curve(labels_test, proba[:,1])\n",
    "#replace these fpr and tpr with the results of your roc_curve\n",
    "fpr, tpr = fpr_result, tpr_result\n",
    "\n",
    "print(roc_auc_score(labels_test, proba[:,1]))\n",
    "\n",
    "# Do not change this code! This plots the ROC curve.\n",
    "# Just replace the fpr and tpr above with the values from your roc_curve\n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
