{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Members: Emily Rude, Ye Sheng, Tiffany Valitis, Leon Cai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Predicting the political affiliations of US Counties\n",
    "\n",
    "The goal of this project is to predict whether a given county in the U.S. leans Democratic or Republican based on characteristics such as age, educational level and racial breakdown, the types of industries that its residents work in, and median income. For the purposes of this project, a county is classified as Democratic if the Democratic presidental candidate had the highest percentage of votes in 2016, and Republican if the Republican presidental candidate had the highest percentage of votes in 2016. The dataset we are using, which shows the Democratic/Republican voting breakdown for every county in the U.S. and the charactersitics of each of these counties can be found [here](https://public.opendatasoft.com/explore/dataset/usa-2016-presidential-election-by-county/export/?disjunctive.state).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may add additional imports\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data and Feature Selection\n",
    "\n",
    "While the given dataset includes a vast amount of information on each county, many of these features can be trimmed because either two or more features are closely correlated to each other and thus not all of those features are needed, or there is little or no correlation between those features and a county's political affiliation. Out of all of the features given in the data set, the features imported below are the most indicative of a county's political characteristics. The percincts feature was left out for example because the votes feature was a similar indicator of the county's size, and the weather features were left out for example because they were lowly correlated to political affiliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from csv file\n",
    "col_names = []\n",
    "for i in range(33):\n",
    "    if i == 0:\n",
    "        col_names.append('State')\n",
    "    if i == 1:\n",
    "        col_names.append('Fips')\n",
    "    if i == 2:\n",
    "        col_names.append('County')\n",
    "    if i == 3:\n",
    "        col_names.append('Votes')\n",
    "    if i == 4:\n",
    "        col_names.append('Republicans 2016')\n",
    "    if i == 5:\n",
    "        col_names.append('Democrats 2016')\n",
    "    if i == 6:\n",
    "        col_names.append('Republicans 2012')\n",
    "    if i == 7:\n",
    "        col_names.append('Republicans 2008')\n",
    "    if i == 8:\n",
    "        col_names.append('Democrats 2012')\n",
    "    if i == 9:\n",
    "        col_names.append('Democrats 2008')\n",
    "    if i == 10:\n",
    "        col_names.append('Less Than High School Diploma')\n",
    "    if i == 11:\n",
    "        col_names.append('At Least High School Diploma')\n",
    "    if i == 12:\n",
    "        col_names.append('At Least Bachelors Degree')\n",
    "    if i == 13:\n",
    "        col_names.append('Graduate Degree')\n",
    "    if i == 14:\n",
    "        col_names.append('Median Earnings 2010')\n",
    "    if i == 15:\n",
    "        col_names.append('Total Population')\n",
    "    if i == 16:\n",
    "        col_names.append('Poverty Rate below federal poverty threshold')\n",
    "    if i == 17:\n",
    "        col_names.append('Management professional and related occupations')\n",
    "    if i == 18:\n",
    "        col_names.append('Service occupations')\n",
    "    if i == 19:\n",
    "        col_names.append('Sales and office occupations')\n",
    "    if i == 20:\n",
    "        col_names.append('Farming fishing and forestry occupations')\n",
    "    if i == 21:\n",
    "        col_names.append('Construction extraction maintenance and repair occupations')\n",
    "    if i == 22:\n",
    "        col_names.append('Production transportation and material moving occupations')\n",
    "    if i == 23:\n",
    "        col_names.append('White')\n",
    "    if i == 24:\n",
    "        col_names.append('Black')\n",
    "    if i == 25:\n",
    "        col_names.append('Hispanic')\n",
    "    if i == 26:\n",
    "        col_names.append('Asian')\n",
    "    if i == 27:\n",
    "        col_names.append('Amerindian')\n",
    "    if i == 28:\n",
    "        col_names.append('Other Race')\n",
    "    if i == 29:\n",
    "        col_names.append('Median Age')\n",
    "    if i == 30:\n",
    "        col_names.append('Uninsured')\n",
    "    if i == 31:\n",
    "        col_names.append('Unemployment')\n",
    "    if i == 32:\n",
    "        col_names.append('Violent crime')\n",
    "        \n",
    "data = pd.read_csv(\"2016_election_dataset.csv\", names = col_names, index_col=False)\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "For counties that are missing information in any of the features selected (particularly a few lowly populated counties in Alaska that are too small to have information on all of these fields), we have decided to drop these records from the dataset (List wise deletion). Only a few records have to be dropped under this scenario, and we still have more than enough records to build an accurate and coherent model.\n",
    "\n",
    "## Labeling the Data\n",
    "\n",
    "Each county is labeled 0 for Republican or 1 for Democrat based on which party had a higher voting percentage in 2016. After these labels are added, the 2016 Democratic and Republican voting percentages are then removed. This is because when we are given a particular county with certain characteristics that we want to predict the political affiliation of, those percentages won't be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Republican is 0, Democrat is 1\n",
    "def label_party (row):\n",
    "    if row['Republicans 2016'] > row['Democrats 2016']:\n",
    "        return 0\n",
    "    if row['Republicans 2016'] < row['Democrats 2016']:\n",
    "        return 1\n",
    "    if row['Republicans 2016'] == row['Democrats 2016']:\n",
    "        return None\n",
    "    \n",
    "def convertToNumber (s):\n",
    "    return int.from_bytes(s.encode(), 'little')\n",
    "\n",
    "# add label\n",
    "data['Party Label'] = data.apply (lambda row: label_party(row), axis=1)\n",
    "\n",
    "states = {\n",
    "        'AK': 1,'AL': 2,'AR': 3,'AS': 4,'AZ': 5,'CA': 6,'CO': 7,'CT': 8,'DC': 9,'DE': 10,'FL': 11,'GA': 12,'GU': 13,'HI': 14,\n",
    "        'IA': 15,'ID': 16,'IL': 17,'IN': 18,'KS': 19,'KY': 20,'LA': 21,'MA': 22,'MD': 23,'ME': 24,'MI': 25,'MN': 26,'MO': 27,\n",
    "        'MP': 28,'MS': 29,'MT': 30,'NA': 31,'NC': 32,'ND': 33,'NE': 34,'NH': 35,'NJ': 36,'NM': 37,'NV': 38,'NY': 39,'OH': 40,\n",
    "        'OK': 41,'OR': 42,'PA': 43,'PR': 44,'RI': 45,'SC': 46,'SD': 47,'TN': 48,'TX': 49,'UT': 50,'VA': 51,'VI': 52, 'VT': 53,\n",
    "        'WA': 54,'WI': 55,'WV': 56,'WY': 57\n",
    "}\n",
    "data['State']=data['State'].map(states)\n",
    "\n",
    "data = data.drop('County', axis=1)\n",
    "data = data.drop('Republicans 2016', axis=1)\n",
    "data = data.drop('Democrats 2016', axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Data Exploration is a good way to gain perspective about our data and possibly identify some trends before doing more analysis on it. We can visualize our data in multiple creative ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n",
    "\n",
    "Creating scatterplots are a good way to determine how highly correlated features are to each other and determine which features are the best indicators of political affiliation. Below, it appears that level of education and ethnic breakdown have a decent amount of correlation to political affiliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Income vs Percent of Republican Voters\"\n",
    "data.plot.scatter('Median Age', 'Republicans 2012')\n",
    "\n",
    "# Percent of Residents College Educated vs Percent of Democratic Voters\"\n",
    "data.plot.scatter('At Least Bachelors Degree', 'Democrats 2012')\n",
    "\n",
    "# Percent of White Residents vs Percent of Republican Voters\"\n",
    "data.plot.scatter('White', 'Republicans 2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graph\n",
    "\n",
    "Emily\n",
    "\n",
    "1) democrats and republicans by percentage in each profession\n",
    "2) education levels for democrat and republican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lesshs = data['Less Than High School Diploma'].mean()\n",
    "avg_hs = data['At Least High School Diploma'].mean()\n",
    "avg_bach = data['At Least Bachelors Degree'].mean()\n",
    "avg_grad = data['Graduate Degree'].mean()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_cords = ['Less Than High School Diploma', 'At Least High School Diploma', 'At Least Bachelors Degree', 'Graduate Degree']\n",
    "y_cords = [avg_lesshs, avg_hs, avg_bach, avg_grad]\n",
    "ax.bar(x_cords,y_cords)\n",
    "ax.set_ylabel('Average Percentages')\n",
    "ax.set_xlabel('Education Levels')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "avg_mang = data['Management professional and related occupations'].mean()\n",
    "avg_serv = data['Service occupations'].mean()\n",
    "avg_sal = data['Sales and office occupations'].mean()\n",
    "avg_farm = data['Farming fishing and forestry occupations'].mean()\n",
    "avg_const = data['Construction extraction maintenance and repair occupations'].mean()\n",
    "avg_prod = data['Production transportation and material moving occupations'].mean()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_cords = ['Management professional and related occupations', 'Service occupations', 'Sales and office occupations', \n",
    "           'Farming fishing and forestry occupations', 'Construction extraction maintenance and repair occupations', \n",
    "           'Production transportation and material moving occupations']\n",
    "y_cords = [avg_mang, avg_serv, avg_sal, avg_farm, avg_const, avg_prod]\n",
    "ax.bar(x_cords,y_cords)\n",
    "ax.set_ylabel('Average Percentages')\n",
    "ax.set_xlabel('Professions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots\n",
    "\n",
    "The Box Plots below give us perspective on some key attributes in the dataset and help us understand what values for these attributes would be outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of median income for 2010\")\n",
    "data.boxplot(['Median Earnings 2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of uninsured voters\")\n",
    "data.boxplot(['Uninsured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of unemployed voters\")\n",
    "data.boxplot(['Unemployment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate analysis\n",
    "\n",
    "In this part, we decided to look only at single features and trying to find analysis of central tendency and measures of dispersion. We calculated the mean, median, mode, standard deviation, minimum, maximum, and range of some features. We also did a box plot to visualize the data better and to find outliers. For most of the features we tested below, the central tendency tends to be close to each other, with relatively small standard deviation. However, the minimum, maximum, and box plots shows that many features have a fair amount of outliers, and these can skew the data heavily in certain methods such as K-nearest neighbor, so knowing which features have a lot of outliers is useful to know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the analysis\n",
    "def toPrint(string):\n",
    "    print(string + \":\")\n",
    "    print(\"Mean: \" + str(data[string].mean()))\n",
    "    print(\"Median: \" + str(data[string].median()))\n",
    "    print(\"Mode: \" + str(data[string].mode().iloc[0]))\n",
    "    print(\"Standard Deviation: \" + str(data[string].std()))\n",
    "    print(\"Min: \" + str(data[string].min()) + \", Max: \" + str(data[string].max()) + \", Range: \" + str(data[string].max() - data[string].min()))\n",
    "    data.boxplot(column=[string])\n",
    "    plt.show()\n",
    "    print()\n",
    "\n",
    "toPrint('At Least High School Diploma')\n",
    "toPrint('At Least Bachelors Degree')\n",
    "toPrint('Median Earnings 2010')\n",
    "toPrint('Poverty Rate below federal poverty threshold')\n",
    "toPrint('Management professional and related occupations')\n",
    "toPrint('White')\n",
    "toPrint('Median Age')\n",
    "toPrint('Uninsured')\n",
    "toPrint('Unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the Data\n",
    "\n",
    "In attempting to build the best model possible to classify our records, we will first test several different classification algorithms on our data and assess the performance of each of them. We will assess each of these algorithms on how accurate they are, and how well they handle class imbalance, and display the results of each of those algorithms. Below, we discuss these two meaures in more detail.\n",
    "\n",
    "### 1) Accuracy\n",
    "\n",
    "Each algorithm will be tested on the data using K-Fold Cross Validation with 10 folds. In the first iteration, the first tenth of the data set will serve as the testing data and have the labels removed. The rest of the dataset will serve as the training data which will be used to build the algorithm. Once the algorithm is built, the testing records will be fed into the algorithm and classified. The alrogithm's classification of those testing records will be compared to the actual labels of those testing records to determine the accuracy of that iteration. In the second iteration, the second tenth of the data set will serve as the testing data while the rest serves as the training data. And so forth until all 10 folds are completed. The accuracy of that algorithm will be the average accuracy among those 10 folds.\n",
    "\n",
    "### 2) Class Imbalance\n",
    "\n",
    "Our dataset contains significantly more Republican than Democratic records given that the Democratic population tends to be more concentrated in urban areas. If our model were to be making mostly Republican predictions and have thus a high accuracy rate, we would want to know if this is because the model can properly distinguish what a Republican county looks like or the model is simply giving Republican labels most of the time without making that distinction. Creating a confusion matrix would be a more effective way to analyze the performance of a model instead of simplying looking at it's accuracy rate.\n",
    "\n",
    "In the matrix, the top left value is the number of True Positive Classifications (number of records classified Republican that were actually Republican. The Bottom left is the number of False Positive Classifications (number of records classified Republican that were actually Democratic). The top right is the number of False Negative Classifications (number of records classified Democratic that were actually Republican). And the bottom right is the nuumber of True Negative Classifications (number of records classified Democratic that were actually Democratic).\n",
    "\n",
    "Thus, in this scenario, we are particulary interested in achieveing a low rate of False Positive Classifications to indicate that the algorithm isn't making mostly Republican predictions simply because the majority class is Republican.\n",
    "\n",
    "Another way to analyze the algorithms performance under this Class Imbalance is calculating Precision and Recall. Precision is the probability that given a Repbulican classification, how likely is it to be correct. And Recall is the probability that given a Republican record, will it be classified as such. In this scenario, we are particularly interested in a high recall rate. The F-measure is also calculated which is a combination of both the precision and recall metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Naive Bayes Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Decision Tree Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imbalance\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 20)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "pca = PCA()\n",
    "scaler = StandardScaler()\n",
    "svc = SVC(gamma='auto')\n",
    "\n",
    "pipeline_svm = Pipeline([('scaler', scaler), ('pca', pca), ('svc', svc)])\n",
    "param_grid = {\n",
    "    'svc__kernel': ['linear', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "y_preds = cross_val_predict(pipeline_svm, features_test, labels_test, cv=10) \n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(svc, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_class = MLPClassifier()\n",
    "pipeline_nn = Pipeline([('scaler', scaler), ('mlp_classifier', mlp_class)])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp_classifier__hidden_layer_sizes': list(range(20, 40, 10)),\n",
    "    'mlp_classifier__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_nn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv=5)\n",
    "print(\"Accuracy: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature Engineering is the process of creating new features in our dataset from a combination of exisiting features. Feature Engineering may improve the performance of the model by creating a feature that is more inditicative of political affiliation than exisiting features, reducing the total number of features that the algorithm has to work with, or a combination of both of these factors.\n",
    "\n",
    "One feature we added was the percentage of residents in Professional industries by adding the percentage of residents in both management and sales occuptions. Residents working in both of these types of professions tend to be of similar economic status. We then deleted the two individual columns in exchange for this new addition, reducing the total number of features used by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voter_turnout (row):\n",
    "    return (row['Votes'] / row['Total Population']) * 100\n",
    "\n",
    "def minority(row):\n",
    "    return (row['Black'] + row['Hispanic'] + row['Asian'] + row['Amerindian'] + row['Other Race'])\n",
    "\n",
    "def professional(row):\n",
    "    return (row['Management professional and related occupations'] + row['Sales and office occupations'])\n",
    "    \n",
    "def manufacturing(row):\n",
    "    return (row['Farming fishing and forestry occupations'] + row['Construction extraction maintenance and repair occupations'] + row['Production transportation and material moving occupations'])\n",
    "    \n",
    "data1 = data.pop('Party Label')    \n",
    "    \n",
    "data['Voter Turnout'] = data.apply (lambda row: voter_turnout(row), axis=1)\n",
    "data['Minority'] = data.apply (lambda row: minority(row), axis=1)\n",
    "data['Professional'] = data.apply (lambda row: professional(row), axis=1)\n",
    "data['Manufacturing'] = data.apply (lambda row: manufacturing(row), axis=1)\n",
    "\n",
    "data = data.drop('Black', axis=1)\n",
    "data = data.drop('Hispanic', axis=1)\n",
    "data = data.drop('Asian', axis=1)\n",
    "data = data.drop('Amerindian', axis=1)\n",
    "data = data.drop('Other Race', axis=1)\n",
    "data = data.drop('Management professional and related occupations', axis=1)\n",
    "data = data.drop('Sales and office occupations', axis=1)\n",
    "data = data.drop('Farming fishing and forestry occupations', axis=1)\n",
    "data = data.drop('Construction extraction maintenance and repair occupations', axis=1)\n",
    "data = data.drop('Production transportation and material moving occupations', axis=1)\n",
    "\n",
    "data['Party Label'] = data1\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "print(\"Features shape: \" + str(features.shape))\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Classification Algorithms\n",
    "\n",
    "We will now run our classification algorithms again with the new features in our dataset to assess to what degree adding or removing certain attributes will affect the accuracy of classifying our data. We will thus display the accuracy and class imblance for each algorithm under these new conditions. Furthermore, there are potential ways that each individual classification algorithm can be optimized based on their unique characteristics and we will explore that as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Naive Bayes Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes has the assumption that all the features in the dataset are indepedent. However, some features are depedent on each other, for example, all the percentages of race will add up to 100%. The following will attempt to remove some features that are dependent on each other to see if it gives a different accuracy. As it turned out, the accuracy decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data = data.copy()\n",
    "\n",
    "nb_data = nb_data.drop('Fips', axis=1)\n",
    "nb_data = nb_data.drop('Democrats 2012', axis=1)\n",
    "nb_data = nb_data.drop('Democrats 2008', axis=1)\n",
    "nb_data = nb_data.drop('Less Than High School Diploma', axis=1)\n",
    "nb_data = nb_data.drop('Minority', axis=1)\n",
    "nb_data = nb_data.drop('Voter Turnout', axis=1)\n",
    "nb_data = nb_data.drop('Professional', axis=1)\n",
    "\n",
    "nb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_labels = nb_data['Party Label']\n",
    "nb_features = nb_data.drop(['Party Label'], axis=1)\n",
    "nb_data.head()\n",
    "\n",
    "print(\"Features shape: \" + str(nb_features.shape))\n",
    "print(\"Labels shape: \" + str(nb_labels.shape))\n",
    "nb_features.head()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(nb_features, nb_labels)\n",
    "\n",
    "nested_score = cross_val_score(clf, nb_features, nb_labels, cv=10)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)\n",
    "\n",
    "predicted_score = cross_val_predict(clf, nb_features, nb_labels, cv = 10)\n",
    "print(confusion_matrix(nb_labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(nb_labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Party Label']\n",
    "features = data.drop(['Party Label'], axis=1)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Decision Tree Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imbalance\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree algorithm is prone to overfitting the given dataset by growing extensively to the point where data fragmentation occurs, causing the algorithm to perform less accurately on new test data. To combat this, we can specify a max tree size for the algorithm which is the maximum number of levels that the tree can grow to. We tried max tree sizes of 5, 10, 15, 20 and 25 to determine which tree size performed the most effectively. The tree size that worked the best was 20 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(5, 30, 5):\n",
    "    \n",
    "    # Max Depth of x\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=x)\n",
    "    clf.fit(features, labels)\n",
    "\n",
    "    # measuring accuracy\n",
    "    nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "    print(\"Accuracy of Decision Tree Classifier with Max Depth of \" + str(x) + \":\", nested_score.mean()*100)\n",
    "\n",
    "    # measuring class imbalance\n",
    "    predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "    print(confusion_matrix(labels, predicted_score))\n",
    "    print()\n",
    "    print(classification_report(labels, predicted_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 15)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbor algorithm is affected by class imbalances - if there is an uneven ratio of one class label to another, it may predict that the majority class is more likely, simply because it has more records. To combat this, we will weight points by the inverse of their distance. In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away. As it so happens, this caused the accuracy to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sk.preprocessing.StandardScaler()\n",
    "pca = sk.decomposition.PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "pipeline = Pipeline(steps = [('standard_scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 15)),\n",
    "    'knn__n_neighbors': list(range(1, 26))\n",
    "}\n",
    "grid = sk.model_selection.GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "k_val = grid.best_params_['knn__n_neighbors']\n",
    "clf = sk.neighbors.KNeighborsClassifier(n_neighbors = k_val, weights='distance')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# measuring accuracy\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy of Weighted KNN Classifier:\", nested_score.mean()*100)\n",
    "\n",
    "# measuring class imblanace\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike greedy algorithms such as the Decision Tree algorithm, the SVM algorithm can be configured to find the most optimal solution to a problem (known as the global minimum) rather than a solution that is optimal in the given circumstances, but not necessary the most optimal overall (known as the local minimum). The issue is that configuring the right kernel function for SVM to find the global minimum is difficult. Below, we try to find a more optimal solution with a different kernel setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "svc = SVC(gamma='auto', degree=8)\n",
    "\n",
    "#TESTING SIGMOID KERNEL \n",
    "print(\"SIGMOID KERNEL:\\n\")\n",
    "svc = SVC(kernel='sigmoid')\n",
    "svc.fit(features_train, labels_train)\n",
    "y_pred = svc.predict(features_test)\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(classification_report(labels_test, y_pred))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "#TESTING SIGMOID KERNEL \n",
    "print(\"RBF KERNEL:\\n\")\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(features_train, labels_train)\n",
    "y_pred = svc.predict(features_test)\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(classification_report(labels_test, y_pred))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "#TESTING SIGMOID KERNEL \n",
    "print(\"POLY KERNEL:\\n\")\n",
    "svc = SVC(kernel='sigmoid')\n",
    "svc.fit(features_train, labels_train)\n",
    "y_pred = svc.predict(features_test)\n",
    "print(confusion_matrix(labels_test, y_pred))\n",
    "print(classification_report(labels_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the SVM algorithm, the Neural Net Algorithm can also find the global minimum of a solution when trained correctly. However, the Neural Net Algorithm can also get stuck at a local minimum when not trained optimally. Below, we will try training the Neural Net Algorithm with different Hidden Layer Values to attempt to find the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING relu activation fuction because it was found to be the most accurate when isolated\n",
    "for x in range(15, 60, 20):\n",
    "    \n",
    "    nn_class = MLPClassifier(hidden_layer_sizes= x, activation='relu')\n",
    "    scores = cross_val_score(nn_class, features, labels, cv=5)\n",
    "    print(\"Accuracy of \" + x + \" hidden layers: \", scores.mean()*100)\n",
    "    predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "    print(confusion_matrix(labels, predicted_score))\n",
    "    print()\n",
    "    print(classification_report(labels, predicted_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling\n",
    "\n",
    "Rather than simplying selecting the highest performing classification algorithm with the most optimal features to classify our data, we can create an even more accurate prediction algorithm by identifying the unique benefits of each classification algorithm, then combining and taggregating the results of multiple algorithms. This is called Ensembling. There are two types of Ensembles. Homogenous Enesemble Classifiers aggregate multiple results of the same type of classification algorithm. Heterogenous Voting Classifiers aggregate multiple results from different types of classification algorithms. Below, we explore a few different Ensembleings to determine the most optimal algorithm for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogenous Bagging Ensemble\n",
    "\n",
    "A Homogenous Bagging Ensemble trains the same classification algorithm multiple different times, but each algorithm is trained with a different randomly selected sample from the dataset. Replacement is obsevered when each of the samples are selected. Below, we will run the bagging ensemble with three different types of classification algorithms. After testing many different classification algorithms above, these three were determined to have the best combination of overall performance and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Decision Trees\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=20))\n",
    "clf.fit(features, labels)\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy with Decision Trees: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))\n",
    "\n",
    "# With Naive Bayes\n",
    "clf = BaggingClassifier(base_estimator=GaussianNB())\n",
    "clf.fit(features, labels)\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy with Naive Bayes: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))\n",
    "\n",
    "# With SVM\n",
    "clf = BaggingClassifier(base_estimator=SVC(gamma='auto'))\n",
    "clf.fit(features, labels)\n",
    "nested_score = cross_val_score(clf, features, labels, cv=10)\n",
    "print(\"Accuracy with SVM: \", nested_score.mean()*100, '\\n')\n",
    "\n",
    "predicted_score = cross_val_predict(clf, features, labels, cv = 10)\n",
    "print(confusion_matrix(labels, predicted_score))\n",
    "print()\n",
    "print(classification_report(labels, predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogenous Random Forest Ensemble With Decision Trees\n",
    "\n",
    "The Random Forest Ensemble is a type of Homogenous Bagging Ensemble that uses Decision Trees. However, Random Forest is unique in that when each Decision Tree is being built, each Decision Tree is only allow to split at a given subset of features at a given point instead of getting to consider all features to split on at every level of building the tree. This in turn creates more variation between the Decision Trees being used in the Ensemble as opposed to running Bagging without Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps = [('rfc', RandomForestClassifier())])\n",
    "param_grid = {\n",
    "    # determined above that 20 was the most optimal value for max_depth\n",
    "    'rfc__max_depth': [20],\n",
    "    'rfc__min_samples_leaf': [8,10,12],\n",
    "    'rfc__max_features': [\"sqrt\", \"log2\"]\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, labels)\n",
    "nested_score = cross_val_score(grid_search, features, labels, cv = 5)\n",
    "print(\"Accuracy:\", nested_score.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogenous Boosting Ensemble\n",
    "\n",
    "A boosting ensembler builds and trains several classifiers sequentially, and each time, the data sampling depends on the performance of previously generated models. Boosting begins by fitting a classifier on the original dataset, then fitting additional copies of the classifier on a weighted dataset (where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "#with Decision Trees -- adaBooster uses decision trees as its default base classifier \n",
    "dt_boost = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(dt_boost, features, labels, cv=5)\n",
    "print(\"Accuracy ADA BOOST:\", scores.mean()*100)\n",
    "y_preds = cross_val_predict(dt_boost, features_test, labels_test, cv=10) \n",
    "print(\"Classification report: \\n\", classification_report(labels_test, y_preds, labels=[0,1]))\n",
    " \n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Gradient Boosting\n",
    "g_boost = GradientBoostingClassifier(n_estimators=100)\n",
    "scores = cross_val_score(g_boost, features, labels, cv=5)\n",
    "print(\"Accuracy GRADIENT BOOST:\", scores.mean()*100)\n",
    "y_preds = cross_val_predict(g_boost, features_test, labels_test, cv=10) \n",
    "print(\"Classification report: \\n\", classification_report(labels_test, y_preds, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterogeneous Stacked Ensemble Using Decision Trees, Naive Bayes, and SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the different classifiers\n",
    "clf_1 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_2 = GaussianNB()\n",
    "clf_3 = SVC(gamma='auto')\n",
    "\n",
    "estimators = [('dt', clf_1), ('nb', clf_2), ('svm', clf_3)]\n",
    "\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators)\n",
    "acc = clf.fit(features_train, labels_train).score(features_test, labels_test)\n",
    "print(\"Accuracy:\", acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a variety of different Ensemblings, we determined that the AdaBoost Homogenous Classifier with Decision Trees as the base classifier was the best performing Ensembling based on accuracy, dealing with class imbalance, and efficiency. This is thus the algorithm that we will use to classify our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "\n",
    "A ROC Curve illustrates the alrogithm's trade off between its True Positive Rate and True Negative Rate. Below, we will compute the ROC Curve for our best Ensembling Algorithm which is the AdaBoost Homogenous Classifier with Decision Trees. The higher percentage of the graph area that is under the curve (AUC or Area Under the Curve), the more accurate the algorithm is. An AUC value of 50% indicates that the algorithm is about as good as random guessing, and the algorithm clearly performs well beyond that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "dt_boost = AdaBoostClassifier(n_estimators=100)\n",
    "dt_boost.fit(features_train, labels_train)\n",
    "\n",
    "proba = dt_boost.predict_proba(features_test)\n",
    "fpr_result, tpr_result, thresholds = roc_curve(labels_test, proba[:,1])\n",
    "fpr, tpr = fpr_result, tpr_result\n",
    "\n",
    "print(roc_auc_score(labels_test, proba[:,1]))\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
